---
  title: Part 2
  exercise_page: true
  quiz_page: false
  published: true
---


<% partial 'partials/material_heading' do %>
  Games
<% end %>

<p>
  This week, we will study a classic AI problem: games.
  The simplest scenario, which we will focus on for the sake of
  clarity, are two-player, perfect-information games such as
  tic-tac-toe and chess.
</p>

<p>
  Another topic that we'll be able to get started with, and continue
  on next week, is reasoning under uncertainty using probability.
</p>

<% partial 'partials/hint', locals: { name: 'Learning objectives of Part 2' } do %>

<table class="table">
  <tr>
    <th>
      Theme
    </th>
    <th>
      Objectives (after the course, you ...)
    </th>
  </tr>
  <tr>
    <td>
      Games and search (continued from last week)
    </td>
    <td>
      <ul>
	<li>can formulate a simple game (such as tic-tac-toe) as a game tree
	<li>can explain and implement the minimax algorithm and depth-limited alpha-beta pruning
	<li>can design a reasonable heuristic evaluation function in a game (e.g., chess)
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      Reasoning under uncertainty (to be continued next week)
    </td>
    <td>
      <ul>
	<li>can express uncertain knowledge in a simple situation using a probabilistic model
	<li>can apply the Bayes theorem to calculate posterior probabilities given evidence in a simple scenario
      </ul>
    </td>
  </tr>
</table>

<% end %>

<% partial 'partials/material_heading' do %>
  Games
<% end %>

<p>
  Maxine and Minnie are true game enthusiasts. They just love games.
  Especially two-person, perfect information games such as tic-tac-toe
  or chess.
</p>

<p>
  One day they were playing tic-tac-toe. Maxine, or Max as her
  friends call her, was playing with X. Minnie, or Min as her
  friends call her, had the Os. The situation was
<pre>
       O| |O
       -+-+-
       X| |
       -+-+-
       X|O|
</pre>
  Max was looking at the board and contemplating her next move, as it
  was her turn, when she suddenly buried her face in her hands in
  despair, looking quite like Garry Kasparov playing Deep Blue in
  1997.
</p>

<p>
  Yes, Min was close to getting three Os on the top row, but Max could
  easily put a stop to that plan. So why was Max so pessimistic?
</p>

<% partial 'partials/material_sub_heading' do %>
  Game Trees 
<% end %>

<p>
  To analyse games and optimal strategies, we will introduce the
  concept of a <b>game tree</b>. The game tree is similar to a search
  tree, such as the one in the Sudoku example discussed at the
  lecture.  (Remember that you should also study the lecture slides in
  addition to this material. Some material may be discussed in one but
  not the other.) The different states of the game are represented by
  nodes in the game tree. The "children" of each node N are the
  possible states that can be achieved from the state corresponding to
  N. In board games, the state of the game is defined by the board
  position and whose turn it is.
</p>

<p>
  Consider, for example, the following game tree which begins
  not at the root but in the middle of the game (because otherwise,
  the tree would be way too big to display).
  <br>
  <img width=80% src="/img/diagrams/tictactoe-tree.png">
  <br>
  The game continues at the board position shown in the root node,
  numbered as (1) at the top, with Min's turn to place O at any of the
  three vacant cells. Nodes (2)--(4) show the board positions
  resulting from each of the three choices respectively. In the next
  step, each node has two possible choices for Max to play X each,
  and so the tree branches again.
</p>

<p>
  The game ends when either player gets a row of three, or when there
  are no more vacant cells. When starting from the above starting
  position, the game always ends in a row of three.
</p>

<p>
  Now consider nodes (5)--(10) on the second layer from the bottom.
  In nodes (7) and (9), the game is over, and Max wins with three X's
  in a row. In the remaining nodes, (5), (6), (8), and (10), the game
  is also practically over, since Min only needs to place her O
  in the only remaining cell to win. We can thus decide that the
  end result, or the <b>value</b> of the game in each of the nodes
  on the second level from the bottom is determined. For the
  nodes that end in Max's victory, we'll say that the value 
  equals +1, and for the nodes that end in Min's victory, we'll say
  that the value is -1.
</p>

<p>
  More interestingly, let's now consider the next level of nodes
  towards the root, nodes (2)--(4). Since we decided that both of the
  children of (2), i.e., nodes (5) and (6), lead to Min's victory, we
  can without hesitation attach the value -1 to node (2) as well.  For
  node (3), the left child (7) leads to Max's victory, +1, but the
  right child (8) leads to Min winning, -1. However, it is Max's turn
  to play, and she will of course choose the left child without
  hesitation. Thus, every time we reach the state in node (3), Max
  wins. Thus we can attach the value +1 to node (3).
</p>

<p>
  The same holds for node (4): again, since Max can choose where to
  put her X, she can always ensure victory, and we attach the value
  +1 to node (4).
</p>

<p>
  So far, we have decided that the value of node (2) is -1, which
  means that if we end up in such a board position, Min can ensure
  winning, and that the reverse holds for nodes (3) and (4): their
  value is +1, which means that Max can be sure to win if she only
  plays her own turn wisely.
</p>

<p>
  Finally, we can deduce that since Min is an experienced player, she
  can reach the same conclusion, and thus she only has one real
  option: give Max an impish grin and play the O in the middle of the
  board.
</p>

<p>
  In the diagram below, we have included the value of each node as
  well as the optimal game play starting at Min's turn in the root
  node.
  <br>
  <img width=80% src="/img/diagrams/tictactoe-values.png">
</p>

<p>
  The value of the root node, which is said to be the <b>value of the
  game</b>, tells us who wins (and how much, if the outcome is not
  just plain win or lose): Max wins if the value of the game is +1,
  Min if the value is -1, and if the value is 0, then the game will
  end in a draw. This all is based on the assumption that both players
  choose what is best for them.
</p>

<p>
  The optimal play can also be deduced from the values of the nodes:
  at any <b>Min node</b>, i.e., node where it is Min's turn, the
  optimal choices are given by those children whose value is minimal,
  and conversely, at any <b>Max node</b>, where it is Max's turn, the
  optimal choices are given the the children whose value is maximal.
</p>

<% partial 'partials/material_sub_heading' do %>
  Minimax Algorithm
<% end %>

<p>
  We can exploit the above concept of the value of the game to obtain
  an algorithm with optimal game play in, theoretically speaking, any
  deterministic, two-person, perfect-information game. Given a state
  of the game, the algorithm simply computes the values of the
  children of the given state and chooses the one that has the maximum
  value if it is Max's turn, and the one that has the minimum value if
  it is Min's turn.
</p>

<p>
  The algorithm can be implemented using the neat recursive
  functions below for Max and Min nodes respectively. This is 
  known as the <b>Minimax algorithm</b> (see <a href="https://en.wikipedia.org/wiki/Minimax">Wikipedia: Minimax</a>).
</p>

<% partial 'partials/code_highlight' do %>
1:  max_value(node):
2:     if end_state(node): return value(node)
3:     v = -Inf
4:     for each child in node.children():
5:        v = max(v, min_value(child))
6:     return v  
<% end %>

<% partial 'partials/code_highlight' do %>
1:  min_value(node):
2:     if end_state(node): return value(node)
3:     v = +Inf
4:     for each child in node.children():
5:        v = min(v, max_value(child))
6:     return v  
<% end %>

<% partial 'partials/exercise', locals: { name: 'Why so serious, Max? (1p)' } do %>

<p>
  Let's return to the tic-tac-toe game described in the beginning
  of this section. To narrow down the space of possible end-games
  to consider, we can observe that Max must clearly place an X on
  the top row to avoid imminent defeat:
  <pre>
       O|X|O
       -+-+-
       X| |
       -+-+-
       X|O|
  </pre>
  Now it's Min's turn to play an O. Evaluate the value of this state
  of the game as well as the other states in the game tree where the
  above position is the root, using the Minimax algorithm.
</p>

<% end %>

<% partial 'partials/hint', locals: { name: 'Sounds good, can I go home now?' } do %>

<p>
  As stated above, the Minimax algorithm can be used to implement
  optimal game play in any deterministic, two-player,
  perfect-information game. Such games include tic-tac-toe, connect
  four, chess, Go, etc. (Rock-paper-scissors is not in this class of
  games since it involves information hidden from the other player;
  nor are Monopoly or backgammon which are not deterministic.) So as
  far as this topic is concerned, is that all folks, can we go home
  now?
</p>

<p>
  The answer is that in theory, yes, but in practice, no. In many
  games, the game tree is simply way too big to traverse in full.  For
  example, in chess the average branching factor, i.e., the average
  number of children (available moves) per node is about 35.  That
  means that to explore all the possible scenarios up to only two
  moves ahead, we need to visit approximately 35 x 35 = 1225 nodes
  -- probably not your favorite pen-and-paper homework exercise...  A
  look-ahead of three moves requires visiting 42875 nodes; four moves
  1500625; and ten moves 2758547353515625 (that's about
  2.7 quadrillion) nodes.
</p>

<p>
  In Go, the average branching factor is estimated to be about 250.
  Go means no-go for Minimax.
</p>

<% end %>

<p>
  Next, we will learn a few more tricks that help us manage massive
  game trees, and that were crucial elements in IBM's Deep Blue
  computer defeating the chess world champion, Garry Kasparov, in 
  1997.
</p>


<% partial 'partials/material_sub_heading' do %>
  Depth-limited minimax and heuristic evalution criteria
<% end %>

<p>
  If we can afford to explore only a small part of the game tree,
  we need a way to stop the minimax recursion before reaching an
  end-node, i.e., a node where the game is over and the winner
  is known. This is achieved by using a <b>heuristic 
    evaluation function</b> that takes as input a board position,
  including the information about which player's turn is next,
  and returns a score that should be an estimate of the likely
  outcome of the game continuing from the given board position.
</p>

<p>
  Good heuristics for chess, for example, typically count the amount
  of material (pieces) weighted by their type: the queen is usually
  considered worth about two times as much as a rook, three times a
  knight or a bishop, and nine times as much as a pawn. The king is of
  course worth more than all other things combined since losing it
  amounts to losing the game. Further, occupying the strategically
  important positions, e.g., near the middle of the board, is
  considered an advantage.
</p>

<p>
  The minimax algorithm presented above requires minimal changes 
  to obtain a <b>depth-limited</b> version where the heuristic
  is returned at all nodes at a given depth limit.
</p>

<% partial 'partials/material_sub_heading' do %>
  Alpha-beta pruning
<% end %>

<p>
  Another breakthrough in game AI, proposed independently by several
  researchers including John McCarthy in and around 1960,
  is <a href="https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">alpha-beta
  pruning</a>. For small game trees, it can be used independently of
  the heuristic evaluation method, and for large trees, the two can be
  combined into a powerful method that has dominated the area of game
  AI for decades.
</p>

<p>
  A good example of the idea behind alpha-beta-pruning can be seen
  in the tic-tac-toe game tree that we discussed above -- scroll
  up and let the image of the root node burn into your retina.
</p>

<p>
  Now simulate the Minimax algorithm at the stage where the value of
  the left child node, -1, has been computed and returned to the
  <code>min_value</code> function. The next step would be to
  call <code>max_value</code> to compute the value of the middle
  child. But hold on! If the left child guarantees victory for Minnie,
  what does it matter how the game ends if she chooses to play any
  other way? As soon as the algorithm finds a child node with the best
  possible outcome for the player whose turn it is, it can make a
  choice and avoid computing the values of all the other child nodes.
</p>

<p>
  To implement this in a similar fashion as the Minimax algorithm
  requires small changes in the <code>min_value</code> and 
  <code>max_value</code> functions. Understanding the connection
  between these changes and the principle illustrated by the above
  pruning example is not as easy as it may sound, so please pay
  close attention to this topic and work out the examples and
  exercises with care.
</p>

<% partial 'partials/code_highlight' do %>
1:  max_value(node, alpha, beta):
2:     if end_state(node): return value(node)
3:     v = -Inf
4:     for each child in node.children():
5:        v = max(v, min_value(child, alpha, beta))
6:        alpha = max(alpha, v)
7:        if alpha >= beta: return v
8:     return v  
<% end %>

<% partial 'partials/code_highlight' do %>
1:  min_value(node, alpha, beta):
2:     if end_state(node): return value(node)
3:     v = +Inf
4:     for each child in node.children():
5:        v = min(v, max_value(child, alpha, beta))
6:        beta = min(beta, v)
7:        if alpha >= beta: return v
8:     return v  
<% end %>

<p>
  An important thing to remember is that the <code>alpha</code> value
  is updated only at the Max nodes, and the <code>beta</code> value is
  updated only at the Min nodes. The updated values are passed as
  arguments down to the children, but not up to the calling parent
  node. (That is, the arguments are passed <i>as values</i>, not <i>as
  references</i> in programming lingo.)
</p>

<p>
  The interpretation <code>alpha</code> and <code>beta</code> is that
  they provide the interval of possible values of the game at the node
  that is being processed:
  <code>alpha</code> &le; value &le; <code>beta</code>. This interval
  is updated during the algorithm, and if at some point, the interval
  shrinks so that <code>alpha = beta</code>, we know the value and
  can return it to the parent node without processing any more
  child nodes. It can also happen that <code>alpha > beta</code>,
  which implies that the current node will never be visited in
  optimal game play, and its processing can likewise be aborted.
</p>

<p>
  When starting the recursion at the root node, we use the minimum and
  maximum value of the game as the <code>alpha</code>
  and <code>beta</code> values respectively. For tic-tac-toe and
  chess, for instance, where the outcome is plain win/loss, this
  is <code>alpha = -1</code> and <code>beta = 1</code>. If the range
  of possible values is not specified in advance, we initialize
  as <code>alpha = -&infin;</code> and <code>beta = &infin;</code>.
</p>

<p>
  It is useful to work out a few examples to really understand the
  beauty of alpha-beta pruning. Here's another tic-tac-toe
  example.
  <br>
  <img width=80% src="/img/diagrams/tictactoe-alphabeta.png">
  <br>
</p>

<p>
  You should simulate the algorithm to see that the two branches
  that are grayed out  indeed get pruned -- therefore, it is
  actually a bit misleading to even show their minimax values
  since the algorithm never computes them.
</p>

<p>
  Remember that the Max nodes (such as the root node) only update
  the <code>alpha</code> value and pass it down to the next
  child node. Check that you reach a situation where 
  <code>alpha=0</code> and  <code>beta=-1</code> in a 
  Min node. Actually you should reach such a situation twice.
</p>

<p>
  Another good example (except for the choice of colors) can be found
  from Bruce Rosen's lecture notes for <i>Fundamentals of Artificial
  Intelligence - CS161</i> at
  UCLA: <a href="http://web.cs.ucla.edu/~rosen/161/notes/alphabeta.html">here</a>.
  Note in particular how he emphasizes the fact that the tree is only
  expanded node by node as the algorithm runs, instead of running the
  algorithm on a full tree as is often suggested by diagrams such as
  the ones we use in this material (shame on us!).  Rosen's example
  also illustrates a scenario where the value of the game is not
  constrained to be -1,0, or +1, and the algorithm starts at the root
  with <code>alpha = -&infin;</code> and
  <code>beta = &infin;</code>.
</p>

<% partial 'partials/exercise', locals: { name: 'Alpha-beta for tic-tac-toe (1p)' } do %>

<p>
  Maxine wants to try again -- best out of three! Minnie agrees and
  after a while, they arrive at the following position
  <pre>
       O|X|O
       -+-+-
       X| |X
       -+-+-
        |O|
  </pre>
  It's again Min's turn to play an O. Evaluate the value of this state
  of the game as well as the other states in the game tree where the
  above position is the root, using alpha-beta pruning. Start the
  recursion by calling <code>min-value(root, -1, 1)</code> where
  <code>root</code> is the above board position.
</p>

<p>
  What is the value of the game, and what are the optimal moves?
</p>

<% end %>

<p>
  Notice that while the left-to-right order of the children of each
  node, i.e., the order in which the children are processed in the
  loop on lines 4--7, is arbitrary, it can have significant impact
  on which branches are pruned.
</p>



