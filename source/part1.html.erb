---
  title: Part 1
  exercise_page: true
  quiz_page: true
  published: true
---


<% partial 'partials/material_heading' do %>
  What is AI?
<% end %>

<p>
  In this first part, we will discuss what we mean when we talk about AI.
  It turns out that there is no exact definition at all, but that the
  field is rather being redefined at all times.
</p>

<p>
  We will also briefly discuss the philosophical aspects of AI: whether
  intelligent behavior implies or requires the existence of a ''mind'', and
  in what extent is consciousness replicable as a computational process.
  However, this course is first and foremost focused on building 
  practically useful AI tools, and we will quickly push considerations 
  about consciousness aside as they tend to be only in the way when 
  designing working solutions to real problems.
</p>

<p>
  The first technical topic, also covered in Part 1, is 
  problem-solving by search, and games.
</p>
  
<% partial 'partials/hint', locals: { name: 'Learning objectives of Part 1' } do %>

<table class="table">
  <tr>
    <th>
      Theme
    </th>
    <th>
      Objectives (after the course, you ...)
    </th>
  </tr>
  <tr>
    <td>
      Philosophy and history of AI
    </td>
    <td>
      <ul>
	<li>can express the basic philosophical problems related to AI
(the difficulty in defining AI and consciousness, acting vs thinking,
Turing test) 
	<li>can distinguish between realistic and unrealistic AI in
science-fiction 
	<li>can describe the contrast between "Good Old Fashioned
AI" (GOFAI) and modern AI approaches 
	<li>know the main-stream developments in the history of AI
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      Games and search
    </td>
    <td>
      <ul>
	<li>can formulate a problem as a graph and apply search algorithms to solve it
	<li>can explain and implement A* search
	<li>can formulate a simple game (such as tic-tac-toe) as a game tree
	<li>can explain and implement the minimax algorithm and depth-limited alpha-beta pruning
	<li>can design a reasonable heuristic evaluation function in a game (e.g., chess)
      </ul>
    </td>
  </tr>
</table>

<% end %>


<% partial 'partials/material_sub_heading' do %>
  A (Very) Brief History of AI
<% end %>

<p>
  Artificial Intelligence (AI) is a subdiscipline of Computer
  Science. Indeed, it is arguably as old as Computer Science itself:
  <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a>
  (1912-1954) proposed the Turing machine -- the formal model
  underlying the theory of computation -- as a model with equivalent
  capacity to carry out calculations as a human being (ignoring
  resource constraints on either side).
</p>

<p>
  The term AI was proposed by John McCarthy (1927-2011) -- often
  referred to as the Father of AI -- as the topic of a summer seminar,
  known as <a href="https://en.wikipedia.org/wiki/Dartmouth_workshop">
  Dartmouth conference</a> held in 1956 at Dartmouth College.
</p>

<p>
  As computers developed to the level where it was feasible to
  experiment with practical AI algorithms in the 1940s and 1950s, the most
  distinctive AI problems were games. Games provided a convenient
  restricted domain that could be formalized easily. Board games such
  as checkers, chess, and (recently quite prominently) Go, have
  inspired countless researchers,  and continue to do so.
</p>

<p>
  Closely related to games, search and planning algorithms were an
  area where AI lead to great advances in the 1960s: in a little
  while, we will be able to admire the beauty of, for example,
  the <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A*
  search algorithm</a> and
  <a href="https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning">alpha-beta
  pruning</a>, and apply them to solve AI problems.</p>

<% partial 'partials/hint', locals: { name: 'The Elusive Definition of AI' } do %>

<p>
  There's an old (geeky) joke that AI is defined as ''cool things that
  computer can't do.'' The joke is that under this definition, AI can
  never make any progress: as soon as we find a way to do something cool
  with a computer, it stops being an AI problem.
</p>

<p>
  However, there is an element of truth in the definition in the sense
  that fifty years ago, for instance, search and planning algorithms
  were considered to belong to the domain of AI. Nowadays algorithms
  such as breadth-first and depth-first search, and A*, are thought 
  (and taught) as belonging to Data Structures and Algorithms.
</p>

<% end %>

<p>
  The history of AI, just like many other fields of science, has
  witnessed the coming and going (and coming back and going again,
  etc.) of various different paradigms. Typically, a particular
  paradigm is adopted by most of the research community and
  ultra-optimistic estimates of progress in the near-future are
  provided. All such scenarios so far have ended up running into
  unsurmountable, unexpected problems and the interest has died
  out. For example, in the 1960s <b>artificial neural networks</b>
  were widely believed to solve all AI problems by imitating the
  learning mechanisms in the nature (such as the human central nervous
  system and the brain, in particular). However, certain negative
  results about the expressibility of certain neural computation
  models quickly lead to pessimism and an <b>AI winter</b> followed.
</p>

<p> 
  The 1980s brought a new wave of AI methods based on logic-based
  methods. So called <b>expert systems</b>, manipulating knowledge
  elicited from domain experts, such as medical doctors, showed
  great promise by solving nicely contained, well-defined 
  ''toy problems'', but turned out to fail every time when they
  were deployed in more complex, real-world problems. The second
  (or the third, depending on the counting) AI winter lasted from the
  late 1980s until the mid-1990s.
</p>
 
<p>
  Currently, since the turn of the millennium, AI has been on the rise
  again. In the late 1990s, the ''classical'' or <b>''Good
  Old-Fashioned AI'' (GOFAI)</b> that addressed crisp, clearly
  defined, and isolated problems begun to be replaced by so called
  <b>''modern AI''</b> (in lack of a better name). Modern AI
  introduced methods that were able to handle uncertain and imprecise
  information, most notably by probabilistic methods, and which had
  the great advantage that it was designed to work in the real world.
  The rise of modern AI has continued until present day, further
  boosted by the come-back of neural networks under the label <b>Deep
  Learning</b>.
</p>

<p>
  Whether the history will repeat itself, and the current boom will be
  once again followed by an AI winter, is a matter that only time can
  tell. Even if it does, the significance of AI in the society is
  going to stay. Today, we live our life surrounded by AI, most of the
  time happily unaware of it: the music that we listen, the products
  that we buy online, the movies and series that we watch, our routes
  of transportation, and the information that we have available, are
  all influenced more and more by AI.
</p>

<p>
  No wonder that you have decided to learn more about AI!
</p>

<p> Being able to apply AI methods and thus to be part of the progress
  of AI is a great way to change the world for the better. And even if
  you wouldn't aspire to become an AI researcher or developer, it is
  almost your duty as a citizen to understand at least the
  fundamentals of AI so that you can better use it: be aware of its
  limitations and enjoy all the goodies it can provide.
</p>

<% partial 'partials/material_sub_heading' do %>
  On the Philosophy of AI
<% end %>



<p>
  The best known contribution to AI by Turing is his <i>imitation
  game</i>, which later became known as the <a href="https://en.wikipedia.org/wiki/Turing_test">Turing test</a>.  In the
  test, a human interrogator interacts with two players, A and B, by
  exchanging written messages (in a ''chat''). If the interrogator
  cannot determine which player, A or B, is a computer and which is a
  human, the computer is said to pass the test.  The argument is that
  if a computer is indistinguishable from a human in a general
  natural language conversation, then it must have reached human-level
  intelligence.
</p>

<p>
  Turing's argument that whether a being is intelligent or not can be
  decided based on the behavior it exhibits has been challenged by
  some. The best known counter-argument is John Searle's
  <a href="http://www.iep.utm.edu/chineser/">Chinese Room</a> thought
  experiment. Searle descibes an experiment where a person who doesn't
  know Chinese is locked in a room. Outside the room is a person who
  can slip notes written in Chinese inside the room through a mail
  slot. The person inside the room is given a large manual where she
  can find detailed instructions for responding to the notes she
  receives from the outside.
</p>

<p>
  Searle argued that that even if the person outside the room gets the
  impression that he is in a conversation with another
  Chinese-speaking person, the person inside the room does <i>not
  understand</i> Chinese. Likewise, his argument continues, even if a
  machine behaves in an intelligent manner, for example, by
  passing the Turing test, it doesn't follow that it <i>is</i>
  intelligent or that it has a ''mind'' in the way that a human
  has. The word ''intelligent'' can also be replaced by the word
  ''self-conscious'' and a similar argument can be made.
</p>

<p>
  The definition of intelligence, natural or artificial, and
  consciousness appears to be extremely evasive and leads to
  apparently never-ending discourse. In an intellectual company, with
  plenty of good Burgundy (Bordeaux will also do), this discussion can
  be quite enjoyable. However, as John
  McCarthy <a href="http://www-formal.stanford.edu/jmc/aiphil/node2.html#SECTION00020000000000000000">pointed
  out</a>, the philosophy of AI is ''unlikely to have any more effect
  on the practice of AI research than philosophy of science generally
  has on the practice of science.''
</p>

<% partial 'partials/exercise', locals: { name: 'What is AI, really? (1p)' } do %>

<p>
  Your first exercise will be to take a look into current AI research.
  Find an AI-related scientific article from recent years. Pick one
  that you can understand, by and large: try to see what the problem
  statement, methodology, and conclusions are, roughly.
</p>

<p>
  Good places to start your search are, e.g., the proceedings of
  <a href="http://www.aaai.org">AAAI</a>,
  <a href="http://www.ijcai.org">IJCAI</a>, and 
  <a href="https://www.eurai.org/activities/ECAI_conferences">ECAI</a>
  conferences or magazine-style publications that may be somewhat less
  technical and intended for broader audiences, such
  as <a href="http://ai-magazine.com/">AI Magazine</a>. However,
  please try to avoid articles that are overly polemic and
  superficial -- the idea is to take a look at <i>academic</i> AI,
  and ignore the BS on my Facebook feed...
</p>

<p>
  Read the article through and answer the following questions:
  <ol>
    <li> What is the research problem?
    <li> Is the topic related to the topics of this course?
    <li> Generally speaking, what impression does the article give
      about modern AI research? Reflect on the history and philosophy of
      AI discussed above.
    <li> What studies would be needed to undertand the article in detail?
    <li> Bonus question: Considering the article you chose, how relevant
      is the ''Terminator'' scenario where AI becomes self-conscious and
      turns against the humankind?
  </ol>
</p>

<% end %>

<% partial 'partials/hint', locals: { name: 'How do I return my solutions?' } do %>

<p>
  Solving the above exercise gives you one point (1p). Some exercises such
  as Ex1.4 below require a bit more effort, and they may give you
  two point (2p). This is indicated in the exercise heading as above.
</p>

<p>
  Solutions to ''pen-and-paper'' exercises such as this one 
  are returned at the exercise sessions where you should make sure
  to mark completed exercises on the sheet that is circulated in
  the beginning.
</p>

<p>
  For programming exercises, you will be able to use the TMC system
  which helps you see whether the solution is correct. However,
  even the TMC exercises are marked at the exercise session.
  In other words, <b>it is not enough to upload the programming
    exercises on TMC to get the points</b>.
</p>

<% end %>



<p>
  We will now put our wine glasses aside, roll our sleeves, and turn
  our minds toward more practical considerations.
  Let's jump to our first technical topic: 
  search and problem-solving.
</p>

<% partial 'partials/material_heading' do %>
  Search and Problem-Solving
<% end %>

<p>
  Many problems can be phrased as search problems. Formulating the
  search space and choosing an appropriate search algorithm often
  requires careful thinking and is an important skill for an AI
  developer.
</p>

<p>
  Basic tree and network traversal algorithms belong to the
  course prerequisites, and you should already be familiar with 
  breadth-first, depth-first, and best-first search (including its
  special case, the A* algorithm). If you forgot the details right
  after taking the exam, no need to worry: we will revisit them
  below.
</p>

<% partial 'partials/material_sub_heading' do %>
  Breadth-First and Depth-First Search
<% end %>

<p>
  To set the scene for discussing more advanced search algorithms,
  such as A*, we begin by defining a generic templace for search
  algorithms.
</p>

<% partial 'partials/code_highlight' do %>
1:  search(start_node):
2:     node_list = list()                # empty list (queue/stack/...)
3:     visited = set()                   # empty set
4:     add start_node to node_list
5:     while list is not empty:
6:        node = node_list.first()       # pick the next node to visit
7:        remove node from node_list
8:        if node not in visited:
9:           visited.add(node)
10:          if goal_node(node):
11:             return node              # goal found
12:          add node.neighbors() to node_list
13:       end if
14:    end while
15:    return None                       # no goal found
<% end %>

<p>
  In the above pseudo-code, <code>node_list</code> holds the nodes to
  be visited. The order in which nodes are taken from the list
  by <code>node_list.first()</code> determines the behavior of the
  search: a queue (first-in, first-out) results in <b>breadth-first
  search (BFS)</b> and a stack (last-in, first-out) results
  in <b>depth-first search (DFS)</b>.
</p>

<p>
  In case of BFS, the operation of adding a node to the list (queue)
  is <i>enqueue</i> and the operation of removing the node that was
  added first is <i>dequeue</i>.
</p>

<p>
  In the case of DFS, the operation of adding a node to the list (stack)
  is <i>push</i>, and the operation of removing the node that was
  added last is <i>pop</i>.
</p>

<p>
  The test <code>goal_node</code> tests whether the goal or target node
  of the search is found. Sometimes the problem is simply to traverse the
  network (or tree) completely in a particular order, and there is no
  goal node. In that case, <code>goal_node</code> simply always returns
  <code>False</code>.
</p>

<% partial 'partials/hint', locals: { name: 'But this isn&rsquo;t how Granma taught it to me!' } do %>
<p>
  You may have seen different versions of search algorithms and wonder why
  this isn't exactly like them. In particular, many students have been
  taught the recursive version of DFS, which indeed is very simple
  and elegant.
</p>

<p>
  You need not worry about the difference too much. Here we simply wanted
  to use the same template for all search methods. The behavior is 
  always the same: for example, the recursive version of DFS actually
  uses a stack to store the state of the search and pops the next
  state from the stack just like our non-recursive version above.
</p>
<% end %>

<p>
  It is quite straighforward to see that BFS will always return the
  path with the fewest transitions to a goal node: if node A is nearer
  to the starting node than node B, the search is expanded to node A
  earlier than to B. You can think of the BFS search as
  a <i>frontier</i> of nodes that gradually progresses outwards from 
  the starting node, so that all nodes at a certain number of 
  steps away are expanded before moving one step ahead.
</p>

<p>
  DFS doesn't guarantee that the shortest path be found, but in some
  cases it doesn't matter. See the lecture slides for an example of
  solving Sudoku puzzles using DFS. Can you think of a reason by
  DFS is a better choice in that problem that BFS?
</p>

<p>
  Here's a simple exercise to make sure BFS and DFS are clear enough.
</p>

<% partial 'partials/exercise', locals: { name: 'Breadth-first and depth-first search (1p)' } do %>

<p>
  <img width=30% src="/img/exercises/ex1/Drawing.png" align=right>
  Consider the (cute) network on the right.
</p>

<p>
  <ol>
    <li> Simulate (on pen-and-paper) breadth-first search starting from
      node A when the goal node is H.
    <li> Do the same with depth-first search.
  </ol>
  In each case, present the contents of the node list (queue or stack)
  at each step of the search. To ensure that everyone gets the same
  result, let's agree that nodes are added to the list in alphabetical
  order.
</p>

<% end %>

<p>
  As we discussed above while drinking red wine, search algorithms don't
  necessarily feel like being very cool AI methods. However, as the
  next two exercises demonstrate, they can actually be used to solve
  tasks that -- most of us would admit -- require intelligence.
</p>

<% partial 'partials/exercise', locals: { name: 'Towers of Hanoi (1p)' } do %>

<p>
  Let's play. Solve the well-known
  puzzle <a href="https://www.britannica.com/topic/Tower-of-Hanoi">Towers
    of Hanoi</a>. The puzzle involves three pegs, and three discs: one
  large, one medium-sized, and one small.  (Actually, there can be any
  number of discs but for the pen-and-paper exercise, three is plenty.)
</p>

<p>In the initial state, all three discs are stacked in the first
  (leftmost) peg. The goal is to move the discs to the third peg.
  You can only move one disc at a time, and it is not allowed to
  put a larger disc on top of a smaller disc.</p>

<p>This pretty picture shows the initial state and the goal state:
<pre>
initial  |     |     |          goal    |     |     |          
state:  ---    |     |          state:  |     |    ---  
       -----   |     |                  |     |   -----     
      =====================         ====================
</pre>
</p>

<p>
  <ol>
    <li> Draw a network diagram where the nodes are all the states
      that can be achieved from the initial state, and the edges
      represent allowed transitions (moves) between them.
    <li> Simulate breadth-first search in the state space.
      <b>Note:</b>You don't have to explicitly specify the
      contents of the queue at each step. It is enough to provide
      the traversal order.
    <li> Do the same with depth-first search.
    <li> Compare the search methods on two accounts: <i>a)</i>
      what is the length of the path that each algorithm finds,
      <i>b)</i> what is the number of states visited during the
      search. <b>Note:</b> It is important to note that these are
      two different things (the length of the path, and the number
      of visited states.)
    <li> Does the result depend on the order in which the neighbors
      of each node are added into the list?
  </ol>
</p>

<p>A bonus exercise: Try to see the symmetry in the state diagram,
  and generalize to <i>n > 3</i> discs.
</p>

<% end %>

<% partial 'partials/exercise', locals: { name: 'Travel Planner (2p)' } do %>

<p>
  Now it's time for this week's highlight: implementing a real AI
  application. It will require some effort, and programming can often
  be slow and frustrating, but stay focused, don't hesitate to ask for
  help, and you'll be ok. Next week, we'll continue working on the
  same application, so your hard work now will make your life easier
  next week.
</p>

<p>
  The task is to read Helsinki tram network -- outdated, we're afraid
  so it's not going to be super useful -- data from a file that we give.
  Implement a program that takes as input the starting point A and
  the destination B, and finds the route from A to B with the
  <i>fewest stops</i> between them. It is quite straightforward to 
  show that such a route can be found by BFS.
</p>

<p>
  We provide a Java template that includes a <code>Stop</code> class
  which can retrieve the neighboring stops. These are the valid
  transitions in the state space.
</p>

<p>
  You can also start from scratch and implement your solution in
  your favorite programming language. In that case, simply take the
  <code>network.json</code> file, which is pretty self-explanatory.
  A hint to python programmers: <code>import json</code>.
</p>

<p>
  If using the Java template (others may find these instructions
  useful too):
  <ol>
    <li>
      Download and open the Maven project in a suitable development
      environment (e.g., Netbeans).
    <li>
      Implement the search algorithm in
      class <code>TravelPlanner</code>.  
    <li>
      In order to be able to
      extract the resulting route after the search ends, construct a
      backward-linked list of <code>Stop</code> objects as the stops
      are added into the queue, each of which has a pointer to the
      previous stop from which the search arrived at the stop in
      question. This way, once you arrive at the destination, you can
      start backtracking along the shortest path until the beginning.
    <li>
      Test your solution on TMC to see that your TravelPlanner works
      as it should and doesn't send you on a detour.
  </ol>
</p>

<p>
  If you don't use TMC, you can test by setting the starting stop as
  <code>1250429(Metsolantie)</code> and the destination as
  <code>1121480(Urheilutalo)</code>. The path (listed backwards) with
  the fewest stops is as follows:
<pre>
1121480(Urheilutalo)[DESTINATION] -> 1121438(Brahenkatu) -> 1220414(Roineentie)
-> 1220416(Hattulantie) -> 1220418(Rautalammintie) -> 1220420(Mäkelänrinne)
-> 1220426(Uintikeskus) -> 1173416(Pyöräilystadion) -> 1173423(Koskelantie)
-> 1250425(Kimmontie) -> 1250427(Käpylänaukio) ->1250429(Metsolantie)[START]
</pre>
</p>

<% end %>

<p>
  Alright. So far, we've refreshed BFS and DFS in our memory and
  applied them to solve some pretty cool applications. To go to the
  next level, we'll bring out the big guns, and talk about best-first
  search (which is <b>not</b> abbreviated in order to avoid confusing
  it with breadth-first search) and the A* algorithm.
</p>

<p>
  
</p>

<% partial 'partials/material_sub_heading' do %>
  Informed Search and A*
<% end %>

<p>
  Often, different transitions in the state space are associated with
  different costs.  For example, doing a task could take
  any time between a few seconds and several hours. Or the distance
  between any two tram stops could be between a hundred meters and half
  a kilometer.  Thus, just counting the <i>number</i> of transitions
  is not enough.
</p>

<p>
  To be able to take into account different costs, we can apply
  <b>best-first search</b>, where the node list is ordered by a given
  criterion. For instance, we can choose to always prefer to expand a
  path with the minimal incurred total cost counting from the starting
  node. This is known as <b>Dijkstra's algorithm</b>. In the special
  case where the cost of all transitions is constant, Dijkstra's
  algorithm is equivalent to BFS.
</p>

<p>
  The generic search algorithm template above still applies, but in
  best-first search, the data structure that holds the nodes on the
  node list is a <b>priority queue</b>. When adding nodes to the
  priority queue on line 14, they are given a cost or a value that is
  then used to order the nodes in the queue.  (Depending on the
  application and whether the aim is to minimize or maximize the
  value, the queue can be a min-priority queue or a max-priority
  queue.)
</p>

<% partial 'partials/hint', locals: { name: 'Alice, Where Art Thou Going?' } do %>

<p>
  If you play around with 
  the <a href="http://qiao.github.io/PathFinding.js/visual/">PathFinding
    applet</a> for a while, using BFS or Dijkstra's algorithm, you
  will quickly notice a problem. The search spreads out to all 
  directions symmetrically without any preference towards the 
  goal.
</p>

<p>
  This is understandable since the choice of the next node to expand
  has nothing to do with the goal. However, if we have some
  way of measuring, even approximately, which nodes are nearer
  to the goal, we can use it to guide the search and
  save a lot of effort by never having to explore unpromising
  paths. This is the idea behind <b>informed search</b>.
</p>

<% end %>

<p>
  Informed search relies on having access to a
  <b>heuristic</b> that associates with each node an estimate of the
  remaining cost from the node to the goal. This can be, for example,
  the distance between the node and the goal measured as the crow
  flies (i.e., Euclidean or geodesic distance -- or in plain words, a
  straight-line distance).
</p>

<p>
  Using the heuristic as the criterion for ordering the nodes in
  the (min-)priority queue will always expand nodes that appear to
  be nearer to the goal according to the heuristic. However, this
  may lead the search astray because the incurred cost of the path
  is not taken into account. A balanced search that takes both the
  incurred cost as well as the estimated remaining cost into account
  is obtained by ordering the (min-)priority queue by
  <pre>
           f(node, cost) = cost + h(node),
  </pre>
  where <code>cost</code> is the value associated with the node when
  it is added to the priority queue, and <code>h(node)</code> is the
  heuristic value, i.e., an estimate of the remaining cost
  from <code>node</code> to the goal. This is the <b>A* search</b>.
  If you try it on
  the <a href="http://qiao.github.io/PathFinding.js/visual/">PathFinding
  applet</a>, you will immediately see that it wipes the floor with
  other, uninformed search methods.
</p>  


<% partial 'partials/material_heading' do %>
  Games
<% end %>

<p>
  Maxine and Minnie are true game enthusiasts. They just love games.
  Especially two-person, perfect information games such as tic-tac-toe
  or chess.
</p>

<p>
  One day they were playing tic-tac-toe. Maxine, or Max as her
  friends call her, was playing with X and Minnie, or Min as her
  friends call her, had the Os. The situation was
<pre>
       O| |O
       -+-+-
       X| |
       -+-+-
       X|O|
</pre>
  Max was looking at the board and contemplating her next move, as it
  was her turn, when she suddenly buried her face in her hands in
  despair, looking quite like Garry Kasparov playing Deep Blue in
  1997.
</p>

<p>
  Yes, Min was close to getting three Os on the top row, but Max could
  easily put a stop to that plan. So why was Max so pessimistic?
</p>

<% partial 'partials/material_sub_heading' do %>
  Game Trees and Minimax Algorithm
<% end %>

<p>
  To analyse games and optimal strategies, we will introduce the
  concept of a <b>game tree</b>. The game tree is similar to a search
  tree, such as the Sudoku example discussed at the lecture.
  (Remember that you should also study the lecture slides in addition
  to this material. Some material may be discussed in one but not the
  other.) So we consider different states of the game and let them
  be the nodes in the game tree, so that the "children" of each 
  node N are the possible states that can be achieved from the 
  state corresponding to N. In board games, the state of the game
  is defined by the board position and whose turn it is.
</p>

<p>
  Consider, for example, the following game tree which begins
  not at the root but in the middle of the game (because otherwise,
  the tree would be way too big to display).
  
  <img width=70% src="/img/drawings/tictactoe-treeg.png" align=middle>

  The game continues at the board position shown in the root node,
  numbered as (1), at the top with Min's turn to place O at any of the
  three vacant cells. Nodes (2)--(4) show the resulting board
  positions, respectively, and have two possible choices for
  Max to play X each.
</p>

<p>
  The game ends when either player gets a row of three, or when there
  are no more vacant cell. When starting from the above starting
  position,§ the game always ends in a row of three.
</p>

<p>
  Now consider nodes (5)--(10) on the second layer from the bottom.
  In nodes (7) and (9), the game is over, and Max wins with three X's
  in a row. In the remaining nodes, (5), (6), (8), and (10), the game
  is also practically over, since Min only needs to place her O
  in the only remaining cell to win. We can thus decide that the
  end result, or the <b>value</b> of the game in each of the nodes
  on the second level from the bottom is determined. For the
  nodes that end in Max's victory, we'll say that the value 
  equals +1, and for the nodes that end in Min's victory, we'll say
  that the value is -1.
</p>

<p>
  More interestingly, let's now consider the next level of nodes
  towards the root, nodes (2)--(4). Since we decided that both
  children of (2), i.e., nodes (5) and (6), lead to Min's victory,
  we can without hesitation attach the value -1 to node (2) as well.
  For node (3), the left child (7) leads to Max's victory, +1,
  but the right child (8) leads to Min winning, -1. However, it
  is Max's turn to play, and she will of course choose the left
  child node without hesitation. Thus, every time we reach the
  state in node (3), which includes the fact that it is Max's turn,
  Max wins, and we can attach the value +1 to such a state.
</p>

<p>
  The same holds for node (4): again, since Max can choose where to
  put her X, she can always ensure victory, and we attach the value
  +1 to node (4).
</p>

<p>
  So far, we have decided that the value of node (2) is -1, which
  means that if we end up in such a board position, Min can ensure
  winning, and that the reverse holds for nodes (3) and (4): their
  value is +1, which means that Max can be sure to win if she only
  plays her own turn wisely.
</p>

<p>
  Finally, we can deduce that since Min is an experienced player, she
  can reach the same conclusion, and thus she only has one real
  option: give Max an impish grin and play the O in the middle of the
  board.
</p>


